{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2c46fe",
   "metadata": {},
   "source": [
    "Based on the code shown in https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_sift.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d271516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import SIFT, match_descriptors, plot_matched_features\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import ProjectiveTransform\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0368377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datafiles and make them grayscale\n",
    "def load_image(path):\n",
    "    return np.array(Image.open(path).convert('L'), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "978b5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=None, sigma=1):\n",
    "    \"\"\"\n",
    "    Standard preprocessing:\n",
    "    - grayscale\n",
    "    - resize (optional)\n",
    "    - normalize (zero mean, unit variance)\n",
    "    - gaussian smoothing\n",
    "    \"\"\"\n",
    "    im = np.array(Image.open(img_path).convert('L'), dtype=np.float32)\n",
    "    if target_size:\n",
    "        im = np.array(Image.fromarray(im).resize(target_size, Image.BICUBIC), dtype=np.float32)\n",
    "    im = (im - np.mean(im)) / (np.std(im) + 1e-8)\n",
    "    return gaussian_filter(im, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68e758bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire courant : c:\\Users\\emmar\\OneDrive\\Polytech\\I5\\Semestre 9 - Oslo\\Data Mining\\Exercices\\Day 5\\Augmented_reality_system\\src\n"
     ]
    }
   ],
   "source": [
    "# Used to acces the name of the folder we are working on : not necessary\n",
    "print(\"Répertoire courant :\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "857fa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors\n",
    "def extract_sift_features(image_filename):\n",
    "    image = preprocess_image(image_filename)\n",
    "    sift = SIFT()\n",
    "    sift.detect_and_extract(image)\n",
    "    return sift.keypoints, sift.descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d45e0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the matches\n",
    "def match_and_plot(img1, img2, keypoints1, descriptors1, keypoints2, descriptors2, title):\n",
    "    matches = match_descriptors(descriptors1, descriptors2, max_ratio=0.6, cross_check=True)\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    plt.gray()\n",
    "    plot_matched_features(image0=img1, image1=img2, \n",
    "                          keypoints0=keypoints1, keypoints1=keypoints2,\n",
    "                          matches=matches, ax=ax, \n",
    "                          keypoints_color='cyan',\n",
    "                          only_matches=True)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute matching accuracy using optional homography\n",
    "def compute_matching_accuracy(keypoints1, keypoints2, matches, homography=None, threshold=5):\n",
    "    \"\"\"\n",
    "    Compute the matching accuracy based on a homography.\n",
    "    If no homography is provided, only the number of matches is printed.\n",
    "    \"\"\"\n",
    "    if homography is None:\n",
    "        print(f\"No homography matrix to work with\")\n",
    "        return None\n",
    "\n",
    "    if matches is None or len(matches) == 0:\n",
    "        print(\"No matches to evaluate.\")\n",
    "        return 0\n",
    "        \n",
    "\n",
    "    correct = 0\n",
    "    for i, j in matches:\n",
    "        pt1 = np.array([*keypoints1[i], 1.0])  # homogeneous coordinates\n",
    "        projected = homography @ pt1\n",
    "        projected /= projected[2]  # normalize\n",
    "\n",
    "        pt2 = keypoints2[j]\n",
    "        error = np.linalg.norm(projected[:2] - pt2)\n",
    "\n",
    "        if error < threshold:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(matches) if matches.size > 0 else 0\n",
    "    #print(f\"Matching Accuracy: {accuracy:.2%} ({correct}/{len(matches)} correct matches)\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92e1147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_homography(keypoints1, keypoints2, descriptors1, descriptors2):\n",
    "    \"\"\"\n",
    "    Create a homography matrix from source points to destination points.\n",
    "    \"\"\"\n",
    "    # Convert descriptors to float32 if needed\n",
    "    descriptors1 = descriptors1.astype(np.float32)\n",
    "    descriptors2 = descriptors2.astype(np.float32)\n",
    "\n",
    "    # Match descriptors using BFMatcher + Lowe ratio test\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    raw_matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in raw_matches:\n",
    "        if m.distance < 0.6 * n.distance:\n",
    "            good_matches.append((m.queryIdx, m.trainIdx))\n",
    "\n",
    "    if len(good_matches) < 4:\n",
    "        print(f\"Not enough matches to estimate homography: {len(good_matches)} found\")\n",
    "        return None, None\n",
    "\n",
    "    matches = np.array(good_matches, dtype=int)\n",
    "    \n",
    "    if matches is None:\n",
    "        print(\"No matches found.\")\n",
    "        return None, None\n",
    "    \n",
    "    src = keypoints1[matches[:, 0]]  # points from image 1\n",
    "    dst = keypoints2[matches[:, 1]]  # corresponding points in image 2\n",
    "\n",
    "    model_robust, inliers = ransac(\n",
    "        (src, dst),\n",
    "        ProjectiveTransform,\n",
    "        min_samples=4,\n",
    "        residual_threshold=2,\n",
    "        max_trials=1000\n",
    "    )\n",
    "    H = model_robust.params \n",
    "    return H, matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce8a2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base(dataset_dir = '../data/images'):\n",
    "    dataset_paths = sorted(Path(dataset_dir).rglob(\"*\"))\n",
    "    records = []\n",
    "\n",
    "    for ref_path in dataset_paths:\n",
    "        print(f\"Currently working on {ref_path}\")\n",
    "        \n",
    "        if ref_path.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\", \".avif\"]:\n",
    "            continue\n",
    "            \n",
    "        img_ref = load_image(str(ref_path))\n",
    "        keypoints_ref, descriptors_ref = extract_sift_features(str(ref_path))\n",
    "\n",
    "        if len(keypoints_ref) == 0:\n",
    "            print(f\" Skipped {ref_path.name} due to missing keypoints\")\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            \"filename\" : ref_path.name,\n",
    "            \"path\": str(ref_path),\n",
    "            \"num_keypoints\": len(keypoints_ref),\n",
    "            \"keypoints\": keypoints_ref,\n",
    "            \"descriptors\": descriptors_ref,\n",
    "            \"image_shape\": img_ref.shape,\n",
    "            \"image\": img_ref,\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eef4ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently working on ..\\data\\images\\city_hall\n",
      "Currently working on ..\\data\\images\\city_hall\\city_hall1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently working on ..\\data\\images\\city_hall\\city_hall2.jpg\n",
      "Currently working on ..\\data\\images\\city_hall\\city_hall3.jpeg\n",
      "Currently working on ..\\data\\images\\city_hall\\city_hall4.jpg\n",
      "Currently working on ..\\data\\images\\fram\n",
      "Currently working on ..\\data\\images\\fram\\fram1.png\n",
      "Currently working on ..\\data\\images\\fram\\fram2.jpeg\n",
      "Currently working on ..\\data\\images\\fram\\fram3.jpeg\n",
      "Currently working on ..\\data\\images\\fram\\fram4.jpg\n",
      "Currently working on ..\\data\\images\\fram\\fram5.avif\n",
      "Currently working on ..\\data\\images\\opera\n",
      "Currently working on ..\\data\\images\\opera\\opera1.jpg\n",
      "Currently working on ..\\data\\images\\opera\\opera2.jpg\n",
      "Currently working on ..\\data\\images\\opera\\opera3.jpeg\n",
      "Currently working on ..\\data\\images\\opera\\opera4.jpg\n",
      "Currently working on ..\\data\\images\\opera\\opera5.jpg\n",
      "Currently working on ..\\data\\images\\palace\n",
      "Currently working on ..\\data\\images\\palace\\palace1.jpg\n",
      "Currently working on ..\\data\\images\\palace\\palace2.jpeg\n",
      "Currently working on ..\\data\\images\\palace\\palace3.jpeg\n",
      "Currently working on ..\\data\\images\\palace\\palace4.jpg\n",
      "Currently working on ..\\data\\images\\palace\\palace5.jpg\n",
      "Currently working on ..\\data\\images\\vigeland\n",
      "Currently working on ..\\data\\images\\vigeland\\vigeland1.jpg\n",
      "Currently working on ..\\data\\images\\vigeland\\vigeland2.jpg\n",
      "Currently working on ..\\data\\images\\vigeland\\vigeland3.jpg\n",
      "Currently working on ..\\data\\images\\vigeland\\vigeland4.png\n"
     ]
    }
   ],
   "source": [
    "data = load_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b531b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_all (ref_path):\n",
    "    ref_path = Path(ref_path)\n",
    "    results_dict = []\n",
    "\n",
    "    if ref_path.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\", \".avif\"]:\n",
    "        pass\n",
    "    \n",
    "    print(f\"Working on {ref_path}\")\n",
    "\n",
    "    img_ref = load_image(str(ref_path))\n",
    "    keypoints_ref, descriptors_ref = extract_sift_features(str(ref_path))\n",
    "\n",
    "    for _, files in data.iterrows():\n",
    "        H1, matches = create_homography(files[\"keypoints\"], keypoints_ref, files[\"descriptors\"], descriptors_ref)\n",
    "        accuracy = compute_matching_accuracy(files['keypoints'], keypoints_ref, matches, H1)\n",
    "        if accuracy is not None:\n",
    "            results_dict.append({\n",
    "                \"test_file\": str(ref_path),\n",
    "                \"compared_file\": files[\"path\"],\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5f728893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ..\\data\\test\\city_hall_test.jpg\n",
      "Not enough matches to estimate homography: 3 found\n",
      "No homography matrix to work with\n",
      "Not enough matches to estimate homography: 2 found\n",
      "No homography matrix to work with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\numeric.py:442: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(res, fill_value, casting='unsafe')\n",
      "C:\\Users\\emmar\\AppData\\Local\\Temp\\ipykernel_5700\\2372129772.py:19: RuntimeWarning: divide by zero encountered in divide\n",
      "  projected /= projected[2]  # normalize\n",
      "C:\\Users\\emmar\\AppData\\Local\\Temp\\ipykernel_5700\\2372129772.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  projected /= projected[2]  # normalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough matches to estimate homography: 3 found\n",
      "No homography matrix to work with\n",
      "Not enough matches to estimate homography: 0 found\n",
      "No homography matrix to work with\n",
      "Not enough matches to estimate homography: 3 found\n",
      "No homography matrix to work with\n",
      "Not enough matches to estimate homography: 0 found\n",
      "No homography matrix to work with\n",
      "Not enough matches to estimate homography: 0 found\n",
      "No homography matrix to work with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skimage\\measure\\fit.py:975: UserWarning: No inliers found. Model not fitted\n",
      "  warn(\"No inliers found. Model not fitted\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mcomparison_all\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/test/city_hall_test.jpg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mcomparison_all\u001b[39m\u001b[34m(ref_path)\u001b[39m\n\u001b[32m     11\u001b[39m keypoints_ref, descriptors_ref = extract_sift_features(\u001b[38;5;28mstr\u001b[39m(ref_path))\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, files \u001b[38;5;129;01min\u001b[39;00m data.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     H1, matches = \u001b[43mcreate_homography\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeypoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescriptors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     accuracy = compute_matching_accuracy(files[\u001b[33m'\u001b[39m\u001b[33mkeypoints\u001b[39m\u001b[33m'\u001b[39m], keypoints_ref, matches, H1)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcreate_homography\u001b[39m\u001b[34m(keypoints1, keypoints2, descriptors1, descriptors2)\u001b[39m\n\u001b[32m     25\u001b[39m dst = keypoints2[matches[:, \u001b[32m1\u001b[39m]]  \u001b[38;5;66;03m# corresponding points in image 2\u001b[39;00m\n\u001b[32m     27\u001b[39m model_robust, inliers = ransac(\n\u001b[32m     28\u001b[39m     (src, dst),\n\u001b[32m     29\u001b[39m     ProjectiveTransform,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     max_trials=\u001b[32m1000\u001b[39m\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m H = \u001b[43mmodel_robust\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m \n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m H, matches\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "results = comparison_all('../data/test/city_hall_test.jpg')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f37a298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_small(ref_path):\n",
    "    filename = os.path.basename(ref_path)  # \"city_hall_test.jpg\"\n",
    "    folder_name = filename.split('_')[0]  # \"city_hall\"\n",
    "\n",
    "    # Extraire le préfixe du nom de fichier (avant le premier \"_\")\n",
    "    data[\"folder_name\"] = data[\"filename\"].str.split(\"_\").str[0]\n",
    "\n",
    "    # Filtrer les lignes correspondant au dossier \"city_hall\"\n",
    "    df_element = data[data[\"path\"].str.contains(folder_name)]\n",
    "\n",
    "    img_ref = load_image(str(ref_path))\n",
    "    keypoints_ref, descriptors_ref = extract_sift_features(str(ref_path))\n",
    "\n",
    "    for _, files in df_element.iterrows() : \n",
    "        H1, matches = create_homography(files[\"keypoints\"], keypoints_ref, files[\"descriptors\"], descriptors_ref)\n",
    "        accuracy = compute_matching_accuracy(files['keypoints'], keypoints_ref, matches, H1)\n",
    "        print(f'Accuracy between {ref_path} and {files['filename']} : {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458ce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/city_hall_test.jpg and city_hall1.jpg : 0.058823529411764705\n",
      "Not enough matches to estimate homography: 3 found\n",
      "No homography matrix to work with\n",
      "Accuracy between ../data/test/city_hall_test.jpg and city_hall2.jpg : None\n",
      "Not enough matches to estimate homography: 2 found\n",
      "No homography matrix to work with\n",
      "Accuracy between ../data/test/city_hall_test.jpg and city_hall3.jpeg : None\n",
      "Accuracy between ../data/test/city_hall_test.jpg and city_hall4.jpg : 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "comparison_small(\"../data/test/city_hall_test.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "955c628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/fram_test.jpg and fram1.png : 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\numeric.py:442: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(res, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/fram_test.jpg and fram2.jpeg : 0.5\n",
      "Accuracy between ../data/test/fram_test.jpg and fram3.jpeg : 0.6666666666666666\n",
      "Accuracy between ../data/test/fram_test.jpg and fram4.jpg : 0.6363636363636364\n",
      "Accuracy between ../data/test/fram_test.jpg and fram5.avif : 0.5\n"
     ]
    }
   ],
   "source": [
    "comparison_small(\"../data/test/fram_test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f2237d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/palace_test.jpg and palace1.jpg : 0.4\n",
      "Accuracy between ../data/test/palace_test.jpg and palace2.jpeg : 0.2\n",
      "Not enough matches to estimate homography: 0 found\n",
      "No homography matrix to work with\n",
      "Accuracy between ../data/test/palace_test.jpg and palace3.jpeg : None\n",
      "Not enough matches to estimate homography: 1 found\n",
      "No homography matrix to work with\n",
      "Accuracy between ../data/test/palace_test.jpg and palace4.jpg : None\n",
      "Accuracy between ../data/test/palace_test.jpg and palace5.jpg : 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "comparison_small(\"../data/test/palace_test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "425fff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/vigeland_test.avif and vigeland1.jpg : 0.8269230769230769\n",
      "Accuracy between ../data/test/vigeland_test.avif and vigeland2.jpg : 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\numeric.py:442: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(res, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy between ../data/test/vigeland_test.avif and vigeland3.jpg : 0.23076923076923078\n",
      "Accuracy between ../data/test/vigeland_test.avif and vigeland4.png : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "comparison_small(\"../data/test/vigeland_test.avif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d4e54da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcomparison_small\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/test/opera_test.avif\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcomparison_small\u001b[39m\u001b[34m(ref_path)\u001b[39m\n\u001b[32m      9\u001b[39m df_element = data[data[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m].str.contains(folder_name)]\n\u001b[32m     11\u001b[39m img_ref = load_image(\u001b[38;5;28mstr\u001b[39m(ref_path))\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m keypoints_ref, descriptors_ref = \u001b[43mextract_sift_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mref_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, files \u001b[38;5;129;01min\u001b[39;00m df_element.iterrows() : \n\u001b[32m     15\u001b[39m     H1, matches = create_homography(files[\u001b[33m\"\u001b[39m\u001b[33mkeypoints\u001b[39m\u001b[33m\"\u001b[39m], keypoints_ref, files[\u001b[33m\"\u001b[39m\u001b[33mdescriptors\u001b[39m\u001b[33m\"\u001b[39m], descriptors_ref)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mextract_sift_features\u001b[39m\u001b[34m(image_filename)\u001b[39m\n\u001b[32m      3\u001b[39m image = preprocess_image(image_filename)\n\u001b[32m      4\u001b[39m sift = SIFT()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43msift\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetect_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sift.keypoints, sift.descriptors\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skimage\\feature\\sift.py:765\u001b[39m, in \u001b[36mSIFT.detect_and_extract\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    759\u001b[39m dog_scalespace = [np.diff(layer, axis=\u001b[32m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m gaussian_scalespace]\n\u001b[32m    761\u001b[39m positions, scales, sigmas, octaves = \u001b[38;5;28mself\u001b[39m._find_localize_evaluate(\n\u001b[32m    762\u001b[39m     dog_scalespace, image.shape\n\u001b[32m    763\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m gradient_space = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_orientation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moctaves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_scalespace\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[38;5;28mself\u001b[39m._compute_descriptor(gradient_space)\n\u001b[32m    771\u001b[39m \u001b[38;5;28mself\u001b[39m.keypoints = \u001b[38;5;28mself\u001b[39m.positions.round().astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skimage\\feature\\sift.py:516\u001b[39m, in \u001b[36mSIFT._compute_orientation\u001b[39m\u001b[34m(self, positions_oct, scales_oct, sigmas_oct, octaves, gaussian_scalespace)\u001b[39m\n\u001b[32m    514\u001b[39m gradient_row = gradient_space[o][\u001b[32m0\u001b[39m][r, c, scales[k]]\n\u001b[32m    515\u001b[39m gradient_col = gradient_space[o][\u001b[32m1\u001b[39m][r, c, scales[k]]\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m r = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m c = c.astype(\u001b[38;5;28mself\u001b[39m.float_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    518\u001b[39m r -= yx[k, \u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "comparison_small(\"../data/test/opera_test.avif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd65ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
