{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2c46fe",
   "metadata": {},
   "source": [
    "Based on the code shown in https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_sift.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3d271516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import SIFT, match_descriptors, plot_matched_features\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import ProjectiveTransform\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e0368377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datafiles and make them grayscale\n",
    "def load_image(path):\n",
    "    return rgb2gray(np.array(Image.open(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "68e758bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire courant : c:\\Users\\coren\\OneDrive\\Bureau\\corentin\\Etudes\\polytech\\cours\\semestre9\\DMC4100\\Assignment5\\Augmented_reality_system\\src\n"
     ]
    }
   ],
   "source": [
    "# Used to acces the name of the folder we are working on : not necessary\n",
    "print(\"Répertoire courant :\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "857fa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors\n",
    "def extract_sift_features(image):\n",
    "    sift = SIFT()\n",
    "    sift.detect_and_extract(image)\n",
    "    return sift.keypoints, sift.descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a84fd",
   "metadata": {},
   "source": [
    "Problem of dimensions for the first two pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "db9c9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_match(img1, img2):\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    return cv2.resize(img2, (w1, h1)) if (h1 != h2 or w1 != w2) else img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d45e0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the matches\n",
    "def match_and_plot(img1, img2, keypoints1, descriptors1, keypoints2, descriptors2, title):\n",
    "    matches = match_descriptors(descriptors1, descriptors2, max_ratio=0.6, cross_check=True)\n",
    "\n",
    "    #img2 = resize_to_match(img1, img2)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    plt.gray()\n",
    "    plot_matched_features(image0=img1, image1=img2, \n",
    "                          keypoints0=keypoints1, keypoints1=keypoints2,\n",
    "                          matches=matches, ax=ax, \n",
    "                          keypoints_color='cyan',\n",
    "                          only_matches=True)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f104c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute matching accuracy using optional homography\n",
    "def compute_matching_accuracy(keypoints1, keypoints2, matches, homography=None, threshold=5):\n",
    "    \"\"\"\n",
    "    Compute the matching accuracy based on a homography.\n",
    "    If no homography is provided, only the number of matches is printed.\n",
    "    \"\"\"\n",
    "    if homography is None:\n",
    "        print(f\"{len(matches)} matches found (no validation)\")\n",
    "        return None\n",
    "\n",
    "    if matches is None or len(matches) == 0:\n",
    "        print(\"No matches to evaluate.\")\n",
    "        return 0\n",
    "\n",
    "    correct = 0\n",
    "    for i, j in matches:\n",
    "        pt1 = np.array([*keypoints1[i], 1.0])  # homogeneous coordinates\n",
    "        projected = homography @ pt1\n",
    "        projected /= projected[2]  # normalize\n",
    "\n",
    "        pt2 = keypoints2[j]\n",
    "        error = np.linalg.norm(projected[:2] - pt2)\n",
    "\n",
    "        if error < threshold:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(matches) if matches.size > 0 else 0\n",
    "    print(f\"Matching Accuracy: {accuracy:.2%} ({correct}/{len(matches)} correct matches)\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c6aff216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(img, keypoint, size=21):\n",
    "    x, y = int(keypoint[0]), int(keypoint[1])\n",
    "    half = size // 2\n",
    "    patch = img[max(0, y - half):y + half + 1, max(0, x - half):x + half + 1]\n",
    "    if patch.shape != (size, size):\n",
    "        return None  # Ignore les bords\n",
    "    return patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2a65d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(patch1, patch2):\n",
    "    \"\"\"\n",
    "    Calcule la corrélation croisée normalisée entre deux patchs d'image.\n",
    "    \n",
    "    Args:\n",
    "        patch1 (np.ndarray): Premier patch (grayscale, 2D array).\n",
    "        patch2 (np.ndarray): Deuxième patch (même taille que patch1).\n",
    "    \n",
    "    Returns:\n",
    "        float: Score de corrélation croisée normalisée (entre -1 et 1).\n",
    "    \"\"\"\n",
    "    if patch1.shape != patch2.shape:\n",
    "        raise ValueError(\"Les deux patchs doivent avoir la même taille.\")\n",
    "\n",
    "    # Centrage des patchs\n",
    "    patch1_mean = patch1 - np.mean(patch1)\n",
    "    patch2_mean = patch2 - np.mean(patch2)\n",
    "\n",
    "    # Calcul du score NCC\n",
    "    numerator = np.sum(patch1_mean * patch2_mean)\n",
    "    denominator = np.sqrt(np.sum(patch1_mean**2) * np.sum(patch2_mean**2))\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Cas dégénéré : patch uniforme\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e0b38c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_by_ncc_parallel(img_ref, img_test, keypoints_ref, keypoints_test, threshold=0.7):\n",
    "    def match_one(i, kp_test):\n",
    "        patch_test = extract_patch(img_test, kp_test)\n",
    "        if patch_test is None:\n",
    "            return None\n",
    "\n",
    "        best_score = -1\n",
    "        best_idx = -1\n",
    "        for j, kp_ref in enumerate(keypoints_ref):\n",
    "            patch_ref = extract_patch(img_ref, kp_ref)\n",
    "            if patch_ref is None:\n",
    "                continue\n",
    "            score = normalized_cross_correlation(patch_test, patch_ref)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = j\n",
    "\n",
    "        if best_score >= threshold:\n",
    "            return cv2.DMatch(_queryIdx=i, _trainIdx=best_idx, _distance=1 - best_score)\n",
    "        return None\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(match_one)(i, kp) for i, kp in enumerate(keypoints_test))\n",
    "    return [m for m in results if m is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e298509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_homography_from_matches(keypoints_ref, keypoints_test, matches, ransac_thresh=5.0):\n",
    "    \"\"\"\n",
    "    Estime l'homographie entre deux images à partir des correspondances de points clés.\n",
    "\n",
    "    Args:\n",
    "        keypoints_ref (list of cv2.KeyPoint): Points clés de l'image de référence.\n",
    "        keypoints_test (list of cv2.KeyPoint): Points clés de l'image test.\n",
    "        matches (list of cv2.DMatch): Correspondances entre les points.\n",
    "        ransac_thresh (float): Seuil RANSAC pour l'estimation robuste.\n",
    "\n",
    "    Returns:\n",
    "        H (np.ndarray): Matrice d'homographie 3x3 ou None si estimation échoue.\n",
    "    \"\"\"\n",
    "    if len(matches) < 4:\n",
    "        return None  # Pas assez de points pour estimer une homographie\n",
    "\n",
    "    pts_ref = np.float32([keypoints_ref[m.trainIdx] for m in matches])\n",
    "    pts_test = np.float32([keypoints_test[m.queryIdx] for m in matches])\n",
    "\n",
    "    H, mask = cv2.findHomography(pts_ref, pts_test, cv2.RANSAC, ransac_thresh)\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0be928bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_index(dataset_dir):\n",
    "    \"\"\"\n",
    "    Analyse toutes les images du dataset et stocke les informations clés dans un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str or Path): Dossier contenant les images de référence.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contenant les informations extraites pour chaque image.\n",
    "    \"\"\"\n",
    "    dataset_paths = sorted(Path(dataset_dir).rglob(\"*\"))\n",
    "    records = []\n",
    "\n",
    "    for ref_path in dataset_paths:\n",
    "        if ref_path.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\", \".avif\"]:\n",
    "            continue\n",
    "\n",
    "        img_ref = load_image(str(ref_path))\n",
    "        keypoints_ref, descriptors_ref = extract_sift_features(img_ref)\n",
    "\n",
    "        if len(keypoints_ref) == 0:\n",
    "            print(f\"⚠️ Skipped {ref_path.name} due to missing keypoints\")\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            \"filename\": ref_path.name,\n",
    "            \"path\": str(ref_path),\n",
    "            \"num_keypoints\": len(keypoints_ref),\n",
    "            \"keypoints\": keypoints_ref,\n",
    "            \"descriptors\": descriptors_ref,\n",
    "            \"image_shape\": img_ref.shape,\n",
    "            \"image\": img_ref\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "022881f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def batch_compare_tests_to_dataset(test_dir, dataset_dir, ncc_threshold=0.7):\n",
    "    dataset_df = build_dataset_index(dataset_dir)\n",
    "    record ={}\n",
    "    \n",
    "    for test_path in sorted(Path(test_dir).glob(\"*\")):\n",
    "        print(f\"\\n🧪 Test image: {test_path.name}\")\n",
    "        img_test = load_image(str(test_path))\n",
    "        keypoints_test, _ = extract_sift_features(img_test)\n",
    "\n",
    "        for _, row in dataset_df.iterrows():\n",
    "            keypoints_ref = row[\"keypoints\"]\n",
    "            img_ref = row[\"image\"]\n",
    "\n",
    "\n",
    "            if len(keypoints_ref) == 0 or len(keypoints_test) == 0:\n",
    "                print(f\"⚠️ Skipped {row['filename']} due to missing keypoints\")\n",
    "                continue\n",
    "\n",
    "            matches = match_by_ncc_parallel(img_ref, img_test, keypoints_ref, keypoints_test, threshold=ncc_threshold)\n",
    "            if not matches:\n",
    "                print(f\"❌ No NCC matches between {row['filename']} and {test_path.name}\")\n",
    "                continue\n",
    "\n",
    "            H = estimate_homography_from_matches(keypoints_ref, keypoints_test, matches)\n",
    "            accuracy = compute_matching_accuracy(keypoints_ref, keypoints_test, matches, H)\n",
    "\n",
    "            print(f\"🔗 Accuracy of {row['filename']} vs {test_path.name}: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "131c99b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Test image: city_hall_test.jpg\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_posixsubprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[250]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbatch_compare_tests_to_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[249]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mbatch_compare_tests_to_dataset\u001b[39m\u001b[34m(test_dir, dataset_dir, ncc_threshold)\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ Skipped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m due to missing keypoints\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m matches = \u001b[43mmatch_by_ncc_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncc_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matches:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m❌ No NCC matches between \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_path.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[246]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mmatch_by_ncc_parallel\u001b[39m\u001b[34m(img_ref, img_test, keypoints_ref, keypoints_test, threshold)\u001b[39m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cv2.DMatch(_queryIdx=i, _trainIdx=best_idx, _distance=\u001b[32m1\u001b[39m - best_score)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_one\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeypoints_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1977\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1974\u001b[39m \u001b[38;5;28mself\u001b[39m._start_time = time.time()\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._managed_backend:\n\u001b[32m-> \u001b[39m\u001b[32m1977\u001b[39m     n_jobs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1978\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1979\u001b[39m     n_jobs = \u001b[38;5;28mself\u001b[39m._effective_n_jobs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1379\u001b[39m, in \u001b[36mParallel._initialize_backend\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1377\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     n_jobs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_kwargs\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.supports_timeout:\n\u001b[32m   1383\u001b[39m         warnings.warn(\n\u001b[32m   1384\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe backend class \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m does not support timeout. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1385\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou have set \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m in Parallel but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1388\u001b[39m             )\n\u001b[32m   1389\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_parallel_backends.py:639\u001b[39m, in \u001b[36mLokyBackend.configure\u001b[39m\u001b[34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmapping_executor_kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idle_worker_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    637\u001b[39m     idle_worker_timeout = \u001b[38;5;28mself\u001b[39m.backend_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33midle_worker_timeout\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m300\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m \u001b[38;5;28mself\u001b[39m._workers = \u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43midle_worker_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_worker_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmemmapping_executor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[38;5;28mself\u001b[39m.parallel = parallel\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_jobs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\executor.py:18\u001b[39m, in \u001b[36mget_memmapping_executor\u001b[39m\u001b[34m(n_jobs, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_memmapping_executor\u001b[39m(n_jobs, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMemmappingExecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\executor.py:48\u001b[39m, in \u001b[36mMemmappingExecutor.get_memmapping_executor\u001b[39m\u001b[34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[39m\n\u001b[32m     45\u001b[39m reuse = _executor_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m _executor_args == executor_args\n\u001b[32m     46\u001b[39m _executor_args = executor_args\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m manager = \u001b[43mTemporaryResourcesManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# reducers access the temporary folder in which to store temporary\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# pickles through a call to manager.resolve_temp_folder_name. resolving\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# the folder name dynamically is useful to use different folders across\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# calls of a same reusable executor\u001b[39;00m\n\u001b[32m     54\u001b[39m job_reducers, result_reducers = get_memmapping_reducers(\n\u001b[32m     55\u001b[39m     unlink_on_gc_collect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     56\u001b[39m     temp_folder_resolver=manager.resolve_temp_folder_name,\n\u001b[32m     57\u001b[39m     **backend_args,\n\u001b[32m     58\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:601\u001b[39m, in \u001b[36mTemporaryResourcesManager.__init__\u001b[39m\u001b[34m(self, temp_folder_root, context_id)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# It would be safer to not assign a default context id (less silent\u001b[39;00m\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# bugs), but doing this while maintaining backward compatibility\u001b[39;00m\n\u001b[32m    598\u001b[39m     \u001b[38;5;66;03m# with the previous, context-unaware version get_memmaping_executor\u001b[39;00m\n\u001b[32m    599\u001b[39m     \u001b[38;5;66;03m# exposes too many low-level details.\u001b[39;00m\n\u001b[32m    600\u001b[39m     context_id = uuid4().hex\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_current_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:605\u001b[39m, in \u001b[36mTemporaryResourcesManager.set_current_context\u001b[39m\u001b[34m(self, context_id)\u001b[39m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_current_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, context_id):\n\u001b[32m    604\u001b[39m     \u001b[38;5;28mself\u001b[39m._current_context_id = context_id\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregister_new_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:627\u001b[39m, in \u001b[36mTemporaryResourcesManager.register_new_context\u001b[39m\u001b[34m(self, context_id)\u001b[39m\n\u001b[32m    623\u001b[39m new_folder_name = \u001b[33m\"\u001b[39m\u001b[33mjoblib_memmapping_folder_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    624\u001b[39m     os.getpid(), \u001b[38;5;28mself\u001b[39m._id, context_id\n\u001b[32m    625\u001b[39m )\n\u001b[32m    626\u001b[39m new_folder_path, _ = _get_temp_dir(new_folder_name, \u001b[38;5;28mself\u001b[39m._temp_folder_root)\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregister_folder_finalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[38;5;28mself\u001b[39m._cached_temp_folders[context_id] = new_folder_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:643\u001b[39m, in \u001b[36mTemporaryResourcesManager.register_folder_finalizer\u001b[39m\u001b[34m(self, pool_subfolder, context_id)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister_folder_finalizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool_subfolder, context_id):\n\u001b[32m    637\u001b[39m     \u001b[38;5;66;03m# Register the garbage collector at program exit in case caller forgets\u001b[39;00m\n\u001b[32m    638\u001b[39m     \u001b[38;5;66;03m# to call terminate explicitly: note we do not pass any reference to\u001b[39;00m\n\u001b[32m    639\u001b[39m     \u001b[38;5;66;03m# ensure that this callback won't prevent garbage collection of\u001b[39;00m\n\u001b[32m    640\u001b[39m     \u001b[38;5;66;03m# parallel instance and related file handler resources such as POSIX\u001b[39;00m\n\u001b[32m    641\u001b[39m     \u001b[38;5;66;03m# semaphores and pipes\u001b[39;00m\n\u001b[32m    642\u001b[39m     pool_module_name = whichmodule(delete_folder, \u001b[33m\"\u001b[39m\u001b[33mdelete_folder\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[43mresource_tracker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_subfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfolder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cleanup\u001b[39m():\n\u001b[32m    646\u001b[39m         \u001b[38;5;66;03m# In some cases the Python runtime seems to set delete_folder to\u001b[39;00m\n\u001b[32m    647\u001b[39m         \u001b[38;5;66;03m# None just before exiting when accessing the delete_folder\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    652\u001b[39m         \u001b[38;5;66;03m# because joblib should only use relative imports to allow\u001b[39;00m\n\u001b[32m    653\u001b[39m         \u001b[38;5;66;03m# easy vendoring.\u001b[39;00m\n\u001b[32m    654\u001b[39m         delete_folder = \u001b[38;5;28m__import__\u001b[39m(\n\u001b[32m    655\u001b[39m             pool_module_name, fromlist=[\u001b[33m\"\u001b[39m\u001b[33mdelete_folder\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    656\u001b[39m         ).delete_folder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\resource_tracker.py:244\u001b[39m, in \u001b[36mResourceTracker.register\u001b[39m\u001b[34m(self, name, rtype)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, rtype):\n\u001b[32m    243\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Register name of resource with resource tracker.'''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mREGISTER\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\resource_tracker.py:261\u001b[39m, in \u001b[36mResourceTracker._send\u001b[39m\u001b[34m(self, cmd, name, rtype)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msg) > \u001b[32m512\u001b[39m:\n\u001b[32m    257\u001b[39m     \u001b[38;5;66;03m# posix guarantees that writes to a pipe of less than PIPE_BUF\u001b[39;00m\n\u001b[32m    258\u001b[39m     \u001b[38;5;66;03m# bytes are atomic, and that PIPE_BUF >= 512\u001b[39;00m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmsg too long\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_running_and_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\resource_tracker.py:220\u001b[39m, in \u001b[36mResourceTracker._ensure_running_and_write\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    218\u001b[39m         msg = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# message was sent in probe\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\resource_tracker.py:185\u001b[39m, in \u001b[36mResourceTracker._launch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _HAVE_SIGMASK:\n\u001b[32m    184\u001b[39m         prev_sigmask = signal.pthread_sigmask(signal.SIG_BLOCK, _IGNORED_SIGNALS)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     pid = \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspawnv_passfds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfds_to_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prev_sigmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\coren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\util.py:515\u001b[39m, in \u001b[36mspawnv_passfds\u001b[39m\u001b[34m(path, args, passfds)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mspawnv_passfds\u001b[39m(path, args, passfds):\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_posixsubprocess\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m\n\u001b[32m    517\u001b[39m     passfds = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, passfds)))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named '_posixsubprocess'"
     ]
    }
   ],
   "source": [
    "batch_compare_tests_to_dataset(\"../data/test\", \"../data/images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
